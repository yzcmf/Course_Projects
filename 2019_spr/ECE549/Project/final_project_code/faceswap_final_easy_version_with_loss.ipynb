{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceswap_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCmvy8uVpOHM",
        "colab_type": "code",
        "outputId": "9644e830-e3c8-47b2-d2fc-d3b19592e46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import platform\n",
        "from tensorflow.python.client import device_lib\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rand\n",
        "import glob\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuGRgFOg0x8B",
        "colab_type": "code",
        "outputId": "0992e83c-ecc0-41a0-c7f9-2e1dc019bcec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://gitlab.uip6.com/github/faceswap.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'faceswap'...\n",
            "remote: Enumerating objects: 2486, done.\u001b[K\n",
            "remote: Counting objects: 100% (2486/2486), done.\u001b[K\n",
            "remote: Compressing objects: 100% (917/917), done.\u001b[K\n",
            "remote: Total 2486 (delta 1558), reused 2486 (delta 1558)\u001b[K\n",
            "Receiving objects: 100% (2486/2486), 173.09 MiB | 1.24 MiB/s, done.\n",
            "Resolving deltas: 100% (1558/1558), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tx5KxylFyz0",
        "colab_type": "code",
        "outputId": "966c8897-713e-4014-c959-d240929ce3ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "import keras.backend as K\n",
        "import keras\n",
        "from keras.models import model_from_json\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Reshape, Activation, Dropout\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.optimizers import Adam\n",
        "from tqdm import tqdm\n",
        "#!pip install moviepy\n",
        "#!pip install keras_vggface\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "#import imageio\n",
        "#imageio.plugins.ffmpeg.download()\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "import faceswap\n",
        "from faceswap.lib.model.layers import PixelShuffler"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1375312069522486487\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 2962518873120497996\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8362559328957145697\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14800692839\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 9770044922417760221\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiIH9KuTpRQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN = 0.0\n",
        "MAX = 255.0\n",
        "IMAGE_EDGE = 64\n",
        "IMAGE_DIM = (IMAGE_EDGE, IMAGE_EDGE, 3)\n",
        "\n",
        "def show_image(image):\n",
        "  imgplot = plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "# Normalize image\n",
        "def preprocess_image(original_image):\n",
        "  processed_image = original_image - MIN\n",
        "  processed_image = (processed_image / (MAX - MIN)) * 2.0\n",
        "  processed_image = processed_image - 1.0\n",
        "  return processed_image\n",
        "\n",
        "# Undo normalization\n",
        "def postprocess_image(processed_image):\n",
        "  unnormalized = processed_image + 1.0\n",
        "  unnormalized = (unnormalized / 2.0) * (MAX - MIN)\n",
        "  unnormalized = unnormalized + MIN\n",
        "  return unnormalized.astype(int)\n",
        "\n",
        "# SETUP IMAGES HERE, Images is array [image number, size of image]\n",
        "\n",
        "img_dirA = 'gdrive/My Drive/facesA/rgb'\n",
        "img_dirB = 'gdrive/My Drive/facesB/rgb'\n",
        "train_A = glob.glob(img_dirA+\"/*.*\")\n",
        "train_B = glob.glob(img_dirB+\"/*.*\")\n",
        "images_a = np.array([np.array(Image.open(fname).resize(IMAGE_DIM[0:2])) for fname in train_A])\n",
        "images_b = np.array([np.array(Image.open(fname).resize(IMAGE_DIM[0:2])) for fname in train_B])\n",
        "scaled_a = preprocess_image(images_a)\n",
        "scaled_b = preprocess_image(images_b)\n",
        "\n",
        "flattendedimages_a = np.array(scaled_a).reshape((scaled_a.shape[0], -1))\n",
        "flattendedimages_b = np.array(scaled_b).reshape((scaled_b.shape[0], -1))\n",
        "# Size of input images to discriminators (SIZE OF IMAGE)\n",
        "assert(flattendedimages_a.shape[1] == flattendedimages_b.shape[1])\n",
        "input_size = flattendedimages_a.shape[1]\n",
        "\n",
        "# Scale images to fit functions\n",
        "scaledimages_a = flattendedimages_a.reshape((-1,)+IMAGE_DIM)\n",
        "scaledimages_b = flattendedimages_b.reshape((-1,)+IMAGE_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiRW9tJ5aQAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_generated_images(epoch, generator, input_images, dim=(10,10), figsize=(10,10), label='a'):\n",
        "    generated_images = generator.predict(input_images)\n",
        "    generated_images = postprocess_image(generated_images.reshape(input_images.shape))\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(input_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(postprocess_image(input_images[i]), interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/gdrive/My Drive/outputs2/input_' + label + '_generated_image_%d.png' %epoch)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/gdrive/My Drive/outputs2/gan_' + label + '_generated_image_%d.png' %epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz17odyapbCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_encoder(latent_size, alpha=0.1):\n",
        "  \n",
        "  inputs = Input(shape=IMAGE_DIM)\n",
        "  \n",
        "  encoder = Reshape(IMAGE_DIM)(inputs)\n",
        "  \n",
        "  encoder = Conv2D(IMAGE_EDGE * 2, kernel_size=5, strides=2, padding='same')(encoder)\n",
        "  encoder = LeakyReLU(alpha)(encoder)\n",
        "  encoder = Conv2D(IMAGE_EDGE * 4, kernel_size=5, strides=2, padding='same')(encoder)\n",
        "  encoder = LeakyReLU(alpha)(encoder)\n",
        "  encoder = Conv2D(IMAGE_EDGE * 8, kernel_size=5, strides=2, padding='same')(encoder)\n",
        "  encoder = LeakyReLU(alpha)(encoder)\n",
        "  encoder = Conv2D(IMAGE_EDGE * 16, kernel_size=5, strides=2, padding='same')(encoder)\n",
        "  encoder = LeakyReLU(alpha)(encoder)\n",
        "\n",
        "  encoder = Flatten()(encoder)\n",
        "  encoder = Dense(latent_size)(encoder)\n",
        "  encoder = Dense(4 * 4 * 1024)(encoder)\n",
        "  encoder = Reshape((4, 4, 1024))(encoder)\n",
        "  \n",
        "  encoder = Conv2D(512 * 4, kernel_size=3, padding='same')(encoder)\n",
        "  encoder = LeakyReLU(alpha)(encoder)\n",
        "  encoder = PixelShuffler()(encoder)\n",
        "  \n",
        "  model = Model(inputs=[inputs],outputs=[encoder])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def create_decoder(out_dim, alpha=0.1):\n",
        "  \n",
        "  inputs = Input(shape=(4, 4, 512 * 4))\n",
        "  \n",
        "  decoder = Reshape((8, 8, 512))(inputs)\n",
        "\n",
        "  decoder = Conv2D(256 * 4, kernel_size=3, padding='same')(decoder)\n",
        "  decoder = LeakyReLU(alpha)(decoder)\n",
        "  decoder = PixelShuffler()(decoder)\n",
        "  \n",
        "  decoder = Conv2D(128 * 4, kernel_size=3, padding='same')(decoder)\n",
        "  decoder = LeakyReLU(alpha)(decoder)\n",
        "  decoder = PixelShuffler()(decoder)\n",
        "  \n",
        "  decoder = Conv2D(64 * 4, kernel_size=3, padding='same')(decoder)\n",
        "  decoder = LeakyReLU(alpha)(decoder)\n",
        "  decoder = PixelShuffler()(decoder)\n",
        "  \n",
        "  decoder = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(decoder)\n",
        "  \n",
        "  decoder = Flatten()(decoder)\n",
        "  decoder = Dense(out_dim)(decoder)\n",
        "  decoder = Dense(64 * 64 * 3)(decoder)\n",
        "  decoder = Activation('tanh')(decoder)\n",
        "  decoder = Reshape(IMAGE_DIM)(decoder)\n",
        "  \n",
        "  model = Model(inputs=[inputs],outputs=[decoder])\n",
        "  \n",
        "  return model\n",
        "\n",
        "def create_discriminator(alpha=0.1, dropout=0.6):\n",
        "  \n",
        "  inputs = Input(shape=IMAGE_DIM)\n",
        "  \n",
        "  discriminator = Reshape(IMAGE_DIM)(inputs)\n",
        "\n",
        "  discriminator = Conv2D(IMAGE_EDGE, kernel_size=5, strides=2, padding='same')(discriminator)\n",
        "  discriminator = LeakyReLU(alpha)(discriminator)\n",
        "  discriminator = Dropout(dropout)(discriminator)\n",
        "  \n",
        "  discriminator = Conv2D(IMAGE_EDGE, kernel_size=5, strides=1, padding='same')(discriminator)\n",
        "  discriminator = LeakyReLU(alpha)(discriminator)\n",
        "  discriminator = Dropout(dropout)(discriminator)\n",
        "  \n",
        "  discriminator = Conv2D(IMAGE_EDGE, kernel_size=5, strides=1, padding='same')(discriminator)\n",
        "  discriminator = LeakyReLU(alpha)(discriminator)\n",
        "  discriminator = Dropout(dropout)(discriminator)\n",
        "  \n",
        "  discriminator = Flatten()(discriminator)\n",
        "  discriminator = Dense(IMAGE_EDGE * 2)(discriminator)\n",
        "  discriminator = LeakyReLU(alpha)(discriminator)\n",
        "  discriminator = Dense(1)(discriminator)\n",
        "  discriminator = Activation('sigmoid')(discriminator)\n",
        "  \n",
        "  model = Model(inputs=[inputs],outputs=[discriminator])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hSxavc4ASIjJ",
        "colab": {}
      },
      "source": [
        "# Loss functions https://github.com/shaoanlu/faceswap-GAN/blob/87146b5995a41363f1d93e32c7c8338b78f80b11/networks/losses.py\n",
        "def first_order(x, axis=1):\n",
        "  img_nrows = x.shape[1]\n",
        "  img_ncols = x.shape[2]\n",
        "  if axis == 1:\n",
        "    return K.abs(x[:, 0:img_nrows - 1, 0:img_ncols - 1, :] - x[:, 1:img_nrows, 0:img_ncols - 1, :])\n",
        "  elif axis == 2:\n",
        "    return K.abs(x[:, 0:img_nrows - 1, 0:img_ncols - 1, :] - x[:, 0:img_nrows - 1, 1:img_ncols, :])\n",
        "  else:\n",
        "    return None  \n",
        "\n",
        "def calc_loss(pred, target, loss='l2'):\n",
        "  if loss.lower() == \"l2\":\n",
        "    return K.mean(K.square(pred - target))\n",
        "  elif loss.lower() == \"l1\":\n",
        "    return K.mean(K.abs(pred - target))\n",
        "  elif loss.lower() == \"cross_entropy\":\n",
        "    return -K.mean(K.log(pred + K.epsilon())*target + K.log(1 - pred + K.epsilon())*(1 - target))\n",
        "  else:\n",
        "    raise ValueError(f'Recieve an unknown loss type: {loss}.')\n",
        "\n",
        "def encoding_loss(y_true,y_pred):\n",
        "  reconstruction_loss = calc_loss(y_pred, y_true, \"l1\")\n",
        "  row_pred_consist = K.abs(y_pred[:, 0:64 - 1, 0:64 - 1, :] - y_pred[:, 1:64, 0:64 - 1, :])\n",
        "  row_true_consist = K.abs(y_true[:, 0:64 - 1, 0:64 - 1, :] - y_true[:, 1:64, 0:64 - 1, :])\n",
        "  col_pred_consist = K.abs(y_pred[:, 0:64 - 1, 0:64 - 1, :] - y_pred[:, 0:64 - 1, 1:64, :])\n",
        "  col_true_consist = K.abs(y_true[:, 0:64 - 1, 0:64 - 1, :] - y_true[:, 0:64 - 1, 1:64, :])\n",
        "  edge_loss_y = calc_loss(row_pred_consist, row_true_consist, \"l1\") * 0.1\n",
        "  edge_loss_x = calc_loss(col_pred_consist, col_true_consist, \"l1\") * 0.1\n",
        "  generator_loss = reconstruction_loss + edge_loss_y + edge_loss_x\n",
        "  return generator_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxJEBPFG5KW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_models():\n",
        "  K.clear_session()\n",
        "  \n",
        "  # Creating GAN models\n",
        "  inputs = Input(shape=IMAGE_DIM)\n",
        "  \n",
        "  gen_opt_a = Adam(lr=1e-3)\n",
        "  gen_opt_b = Adam(lr=1e-3)\n",
        "  encoder = create_encoder(1024)\n",
        "  decoder_a = create_decoder(1024)\n",
        "  decoder_b = create_decoder(1024)\n",
        "  generator_a = Model(inputs, decoder_a(encoder(inputs)))\n",
        "  generator_b = Model(inputs, decoder_b(encoder(inputs)))\n",
        "  generator_a.compile(loss='binary_crossentropy', optimizer=gen_opt_a)\n",
        "  generator_b.compile(loss='binary_crossentropy', optimizer=gen_opt_b)\n",
        "  \n",
        "  disc_opt_a = Adam(lr=1e-4)\n",
        "  disc_opt_b = Adam(lr=1e-4)\n",
        "  discriminator_a = create_discriminator()\n",
        "  discriminator_b = create_discriminator()\n",
        "  discriminator_a.compile(loss='binary_crossentropy', optimizer=disc_opt_a)\n",
        "  discriminator_b.compile(loss='binary_crossentropy', optimizer=disc_opt_b)\n",
        "  \n",
        "  def make_trainable(net, val):\n",
        "    net.trainable = val\n",
        "    for l in net.layers:\n",
        "        l.trainable = val\n",
        "        \n",
        "  make_trainable(discriminator_a, False)\n",
        "  make_trainable(discriminator_b, False)\n",
        "  fake_a = generator_a(inputs)\n",
        "  fake_b = generator_b(inputs)\n",
        "  validity_a = discriminator_a(fake_a)\n",
        "  validity_b = discriminator_b(fake_b)\n",
        "  GAN_a = Model(inputs, [fake_a, validity_a])\n",
        "  GAN_b = Model(inputs, [fake_b, validity_b])\n",
        "  GAN_a.compile(loss=[encoding_loss, 'binary_crossentropy'], optimizer=gen_opt_a, loss_weights=[1,0.1])\n",
        "  GAN_b.compile(loss=[encoding_loss, 'binary_crossentropy'], optimizer=gen_opt_b, loss_weights=[1,0.1])\n",
        "  \n",
        "  return generator_a, generator_b, discriminator_a, discriminator_b, GAN_a, GAN_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLfbrCTybSsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(generator_a, generator_b, discriminator_a, discriminator_b, GAN_a, GAN_b, imageset_a, imageset_b, past_epochs, epochs=100, batch_size=128):\n",
        "  start = time.time()\n",
        "  gen_a_losses = []\n",
        "  gen_b_losses = []\n",
        "  disc_a_losses = []\n",
        "  disc_b_losses = []\n",
        "  for e in range(1,epochs+1 ):\n",
        "    np.random.shuffle(imageset_a)\n",
        "    np.random.shuffle(imageset_b)\n",
        "    for ii in range(min(imageset_a.shape[0]//batch_size, imageset_b.shape[0]//batch_size)):\n",
        "      # image inputs\n",
        "      batch_a = np.array(imageset_a[ii*batch_size:(ii+1)*batch_size])\n",
        "      batch_b = np.array(imageset_b[ii*batch_size:(ii+1)*batch_size])\n",
        "\n",
        "      # Generate fake images from other image inputs\n",
        "      generated_images_a = generator_a.predict(batch_b)\n",
        "      generated_images_b = generator_b.predict(batch_a)\n",
        "\n",
        "      #Construct different batches of  real and fake data \n",
        "      X_a = np.concatenate([batch_a, generated_images_a])\n",
        "      X_b = np.concatenate([batch_b, generated_images_b])\n",
        "      # Labels for generated and real data\n",
        "      y_dis=np.zeros(2*batch_size).reshape((2*batch_size,1))\n",
        "      y_dis[:batch_size]=0.9\n",
        "\n",
        "      #Pre train discriminator on  fake and real data  before starting the gan. \n",
        "      discriminator_a.trainable=True\n",
        "      discriminator_a.train_on_batch(X_a, y_dis)\n",
        "      discriminator_b.trainable=True\n",
        "      discriminator_b.train_on_batch(X_b, y_dis)\n",
        "\n",
        "      y_gen = np.ones(batch_size).reshape((batch_size,1))\n",
        "\n",
        "      # During the training of gan, \n",
        "      # the weights of discriminator should be fixed. \n",
        "      #We can enforce that by setting the trainable flag\n",
        "      discriminator_a.trainable=False\n",
        "      discriminator_b.trainable=False\n",
        "\n",
        "      #training  the GAN by alternating the training of the Discriminator \n",
        "      #and training the chained GAN model with Discriminator’s weights freezed.\n",
        "      GAN_a.train_on_batch(batch_b, [batch_a, y_gen])\n",
        "      GAN_b.train_on_batch(batch_a, [batch_b, y_gen])\n",
        "      \n",
        "    if e % 10 == 0:\n",
        "      generator_a_json = generator_a.to_json()\n",
        "      with open(\"/content/gdrive/My Drive/checkpoints_noise/generator_a.json\", \"w\") as json_file:\n",
        "          json_file.write(generator_a_json)\n",
        "      generator_a.save_weights(\"/content/gdrive/My Drive/checkpoints_noise/generator_a.h5\")\n",
        "      generator_b_json = generator_b.to_json()\n",
        "      with open(\"/content/gdrive/My Drive/checkpoints_noise/generator_b.json\", \"w\") as json_file:\n",
        "          json_file.write(generator_b_json)\n",
        "      generator_b.save_weights(\"/content/gdrive/My Drive/checkpoints_noise/generator_b.h5\")\n",
        "      discriminator_a_json = discriminator_a.to_json()\n",
        "      with open(\"/content/gdrive/My Drive/checkpoints_noise/discriminator_a.json\", \"w\") as json_file:\n",
        "          json_file.write(discriminator_a_json)\n",
        "      discriminator_a.save_weights(\"/content/gdrive/My Drive/checkpoints_noise/discriminator_a.h5\")\n",
        "      discriminator_b_json = discriminator_b.to_json()\n",
        "      with open(\"/content/gdrive/My Drive/checkpoints_noise/discriminator_b.json\", \"w\") as json_file:\n",
        "          json_file.write(discriminator_b_json)\n",
        "      discriminator_b.save_weights(\"/content/gdrive/My Drive/checkpoints_noise/discriminator_b.h5\")\n",
        "      GAN_a_json = GAN_a.to_json()\n",
        "      with open(\"/content/gdrive/My Drive/checkpoints_noise/GAN_a.json\", \"w\") as json_file:\n",
        "          json_file.write(GAN_a_json)\n",
        "      GAN_a.save_weights(\"/content/gdrive/My Drive/checkpoints_noise/GAN_a.h5\")\n",
        "      GAN_b_json = GAN_b.to_json()\n",
        "      with open(\"/content/gdrive/My Drive/checkpoints_noise/GAN_b.json\", \"w\") as json_file:\n",
        "          json_file.write(GAN_b_json)\n",
        "      GAN_b.save_weights(\"/content/gdrive/My Drive/checkpoints_noise/GAN_b.h5\")\n",
        "    if e % 100 == 0:\n",
        "      # image inputs\n",
        "      batch_a = np.array(imageset_a[0:batch_size])\n",
        "      batch_b = np.array(imageset_b[0:batch_size])\n",
        "      plot_generated_images(e + past_epochs, generator_a, batch_b, label='a')\n",
        "      plot_generated_images(e + past_epochs, generator_b, batch_a, label='b')\n",
        "      plot_generated_images(e + past_epochs, generator_a, batch_a, label='a_true')\n",
        "      plot_generated_images(e + past_epochs, generator_b, batch_b, label='b_true')\n",
        "    # Calculate losses\n",
        "    \"\"\"if e % 100 == 0:\n",
        "      generator_out_a = generator_a.predict(imageset_b)\n",
        "      generator_out_b = generator_b.predict(imageset_a)\n",
        "      images_a = np.concatenate([imageset_a, generator_out_a])\n",
        "      images_b = np.concatenate([imageset_b, generator_out_b])\n",
        "      labels=np.zeros(imageset_a.shape[0] + imageset_b.shape[0]).reshape((imageset_a.shape[0] + imageset_b.shape[0],1))\n",
        "      labels[:imageset_a.shape[0]]=0.9\n",
        "\n",
        "      y_true = K.variable(labels)\n",
        "      y_pred =  K.variable(discriminator_a.predict(images_a))\n",
        "      loss = np.mean(K.eval(binary_crossentropy(y_true, y_pred)))\n",
        "      disc_a_losses.append(loss)\n",
        "\n",
        "      labels=np.zeros(imageset_a.shape[0] + imageset_b.shape[0]).reshape((imageset_a.shape[0] + imageset_b.shape[0],1))\n",
        "      labels[:imageset_b.shape[0]]=0.9\n",
        "\n",
        "      y_true =  K.variable(labels)\n",
        "      y_pred =  K.variable(discriminator_b.predict(images_b))\n",
        "      loss = np.mean(K.eval(binary_crossentropy(y_true, y_pred)))\n",
        "      disc_b_losses.append(loss)\n",
        "\n",
        "      y_true =  K.variable(imageset_a[:min(imageset_a.shape[0],imageset_b.shape[0])])\n",
        "      y_pred =  K.variable(generator_a.predict(imageset_b)[:min(imageset_a.shape[0],imageset_b.shape[0])])\n",
        "      loss = K.eval(encoding_loss(y_true,y_pred))\n",
        "      gen_a_losses.append(loss)\n",
        "\n",
        "      y_true =  K.variable(imageset_b[:min(imageset_a.shape[0],imageset_b.shape[0])])\n",
        "      y_pred =  K.variable(generator_b.predict(imageset_a)[:min(imageset_a.shape[0],imageset_b.shape[0])])\n",
        "      loss = K.eval(encoding_loss(y_true,y_pred))\n",
        "      gen_b_losses.append(loss)\"\"\"\n",
        "  print(\"Time elapsed: \", (time.time()-start), \" seconds\")\n",
        "  return generator_a, generator_b, discriminator_a, discriminator_b, GAN_a, GAN_b, gen_a_losses, gen_b_losses, disc_a_losses, disc_b_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_eOztLR_EkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "36288c64-2d08-4fd3-b7de-89c04340b3fa"
      },
      "source": [
        "reuse = False\n",
        "if not reuse:\n",
        "  generator_a, generator_b, discriminator_a, discriminator_b, GAN_a, GAN_b = create_models()\n",
        "else:\n",
        "  json_file = open('/content/gdrive/My Drive/checkpoints_noise/generator_a.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  generator_a = model_from_json(loaded_model_json)\n",
        "  generator_a.load_weights(\"/content/gdrive/My Drive/checkpoints_noise/generator_a.h5\")\n",
        "  \n",
        "  json_file = open('/content/gdrive/My Drive/checkpoints_noise/generator_b.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  generator_b = model_from_json(loaded_model_json)\n",
        "  generator_b.load_weights(\"/content/gdrive/My Drive/checkpoints_noise/generator_b.h5\")\n",
        "  \n",
        "  json_file = open('/content/gdrive/My Drive/checkpoints_noise/discriminator_a.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  discriminator_a = model_from_json(loaded_model_json)\n",
        "  discriminator_a.load_weights(\"/content/gdrive/My Drive/checkpoints_noise/discriminator_a.h5\")\n",
        "  \n",
        "  json_file = open('/content/gdrive/My Drive/checkpoints_noise/discriminator_b.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  discriminator_b = model_from_json(loaded_model_json)\n",
        "  discriminator_b.load_weights(\"/content/gdrive/My Drive/checkpoints_noise/discriminator_b.h5\")\n",
        "  \n",
        "  json_file = open('/content/gdrive/My Drive/checkpoints_noise/GAN_a.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  GAN_a = model_from_json(loaded_model_json)\n",
        "  GAN_a.load_weights(\"/content/gdrive/My Drive/checkpoints_noise/GAN_a.h5\")\n",
        "  \n",
        "  json_file = open('/content/gdrive/My Drive/checkpoints_noise/GAN_b.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  GAN_b = model_from_json(loaded_model_json)\n",
        "  GAN_b.load_weights(\"/content/gdrive/My Drive/checkpoints_noise/GAN_b.h5\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQf-G4iyf9Pd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "1f01bdcc-f854-4f93-81cc-8da541933b4a"
      },
      "source": [
        "epochs = 2000\n",
        "batch_size = 100\n",
        "past_epochs = 0\n",
        "generator_a, generator_b, discriminator_a, discriminator_b, GAN_a, GAN_b, gen_a_losses, gen_b_losses, disc_a_losses, disc_b_losses = training(generator_a, generator_b, discriminator_a, discriminator_b, GAN_a, GAN_b, scaledimages_a, scaledimages_b, past_epochs, epochs, batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  max_open_warning, RuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtXRsUOFKusn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global graph\n",
        "graph = tf.get_default_graph() \n",
        "with graph.as_default():\n",
        "  random_input = np.random.rand(1,64,64,3)*2 - 1\n",
        "  show_image(postprocess_image(generator_b.predict(random_input).reshape(64,64,3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxtAameq6gLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(gen_a_losses, color='blue')\n",
        "plt.plot(gen_b_losses, color='green')\n",
        "plt.plot(disc_a_losses, color='red')\n",
        "plt.plot(disc_b_losses, color='purple')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}